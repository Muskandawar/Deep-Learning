{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrRWNrMihgI3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9c818b3a-3f0e-40f9-83a2-1a551ca78406"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsWt9xmbx5rB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install Theano\n",
        "!pip install keras\n",
        "!pip install tensorflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUc4yuvWhJoO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "63724230-d1a7-49fe-a788-25309a84fc05"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Convolution2D,MaxPooling2D,Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QE1atborq4XG",
        "colab_type": "text"
      },
      "source": [
        "**ANN**\n",
        "\n",
        "Neuron - input is dependant var output is independant var frst step is calculating sum of dependdant var * weights then applying activation function then prediction\n",
        "\n",
        "Activation functions\n",
        "\n",
        "Purpose is to add non-linearity \n",
        "\n",
        "x is value of weighted sum\n",
        "1. Threshold function-> if x>=0 then phi=1 else phi=0\n",
        "2. Sigmoid function-> phi(x)=1/1+e^-x very useful in predicting output layer as it based on probability\n",
        "3. Rectifier function-> phi(x)=max(x,0) \n",
        "4. Hyperbolic tangent-> phi(x)=1-e^-2x/1+e^-2x \n",
        "\n",
        "In hidden layer rectifier func is used while after that sigmoid is used frequently\n",
        "\n",
        "Most common cost function is 1/2(ypred-y)^2 goal->minimize cost func and this is convex func\n",
        "\n",
        "Send the cost func again to nn then update the weights and again feed it find cost value again repeat till it got min value\n",
        "\n",
        "**GRADIENT DESCENT**\n",
        "\n",
        "It is used to minimize the cost function by going zig-zag throughout.used in convex functions\n",
        "\n",
        "**STOCHASTIC GRADIENT DESCENT**\n",
        "\n",
        "We take on row at a time and operate and adjust weights then move to next.It is faster than gradient as it takes row one by one so data is lighter.\n",
        "\n",
        "**BACK-PROPAGATION**\n",
        "\n",
        "Errors are backpropagated. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Quq9LLuR0lcq",
        "colab_type": "text"
      },
      "source": [
        "**WHICH ACTIVATION FUNC TO USE?**\n",
        "\n",
        "For example, if you want your neural network to predict values that are larger than 1, then tanh or sigmoid are not suitable to be used in the output layer, and we must use ReLU instead.\n",
        "\n",
        "On the other hand, if we expect the output values to be in the range [0,1] or [-1, 1] then ReLU is not a good choice for the output layer and we must use sigmoid or tanh.\n",
        "\n",
        "If you perform a classification task and want the neural network to predict a probability distribution over the mutually exclusive class labels, then the softmax activation function should be used in the last layer.\n",
        "\n",
        "However, regarding the hidden layers, as a rule of thumb, I would strongly suggest you always to use ReLU as an activation for these layers.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0feEJ1s1P68a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset=pd.read_csv('/content/drive/My Drive/Churn_Modelling.csv')\n",
        "X=dataset.iloc[:,3:13].values\n",
        "y=dataset.iloc[:,13].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuXhzJvV25lL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_encoder_X1 = LabelEncoder()\n",
        "X[:,1] = label_encoder_X1.fit_transform(X[:,1])\n",
        "label_encoder_X2 = LabelEncoder()\n",
        "X[:,2] = label_encoder_X2.fit_transform(X[:,2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlqTecHW7fsy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "onehot_encoder = ColumnTransformer([('Geography', OneHotEncoder(), [1])], remainder='passthrough')\n",
        "X = onehot_encoder.fit_transform(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4Zhau_u8Oe6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to avoid dummy var trap\n",
        "X=X[:,1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_uFZfsw1ZhM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwAOGaBt1aKl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sc_X=StandardScaler()\n",
        "X_train=sc_X.fit_transform(X_train)\n",
        "X_test=sc_X.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFZAu4bL8j0A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier=Sequential()\n",
        "# adding input and first hidden layer\n",
        "# more value closer to one of act. func. more activated neuron is i.e more better\n",
        "classifier.add(Dense(output_dim=6,init='uniform',activation='relu',input_dim=11)) # output_dim is avg of input and output variables i.e 11+1/2\n",
        "classifier.add(Dense(output_dim=6,init='uniform',activation='relu')) \n",
        "#output layer\n",
        "classifier.add(Dense(output_dim=1,init='uniform',activation='sigmoid'))  # for more classes use softmax and output_dim=3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhO9vXCum2bj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compiling ann\n",
        "classifier.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy']) # loss is lograthmic loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mnol6gRPqgbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#fit model\n",
        "classifier.fit(X_train,y_train,batch_size=10,nb_epoch=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzfvLQAL1cLC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred=classifier.predict(X_test)\n",
        "y_pred=(y_pred>0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6p41wsqgssRO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accuracy_score(y_test,y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yo0wucC1fvP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cm=confusion_matrix(y_test,y_pred)\n",
        "cm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAd-ECrvtLBn",
        "colab_type": "text"
      },
      "source": [
        "**CNN**\n",
        "\n",
        "Convolution is done by feature detector and gives feature map which are relevant features of image.\n",
        "\n",
        "Convolutional layer is group of feature maps.\n",
        "\n",
        "Relu Layer-> apply rectifier to conv layer. Motive is to inc non-linearity.\n",
        "It removes all black values i.e negative val.\n",
        "\n",
        "In backpropagation,not only weights are adjusted but also feature detectors too.\n",
        "\n",
        "**WHY LEAKY RELU?**\n",
        "\n",
        "Another problem we see in ReLU is the Dying ReLU problem where some ReLU Neurons essentially die for all inputs and remain inactive no matter what input is supplied, here no gradient flows and if large number of dead neurons are there in a Neural Network it’s performance is affected, this can be corrected by making use of what is called Leaky ReLU where slope is changed left of x=0 in above figure and thus causing a leak and extending the range of ReLU.\n",
        "\n",
        "**MAX POOLING**\n",
        "\n",
        "Select max value from window. It is used to make image invariant to anything.\n",
        "As max value will remain same.Reducing no. of parameters.Removing more irrelevant info.\n",
        "\n",
        "**FLATTENING**\n",
        "\n",
        "After pooling,flatten matrix to one column.As we will, later input to ann.\n",
        "\n",
        "**FULLY CONNECTED LAYER**\n",
        "\n",
        "Now adding full ann to flattened and hidden layer should be fully connected."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nl97d_XdLmAI",
        "colab_type": "text"
      },
      "source": [
        "**SOFTMAX AND CROSS ENTROPY**\n",
        "\n",
        "Softmax func brings value of output classifier btw 0 and 1 so that prob sum should be one.Cross entropy is cost func which we need to minimize.\n",
        "\n",
        "Cross->better for classification\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_T02cZmzABxg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier=Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arH1zzxMV7OT",
        "colab_type": "text"
      },
      "source": [
        "How to improve this cnn?\n",
        "Add one more conv layer after max pooling\n",
        "\n",
        "classifier.add(Convolution2D(32,3,3,activation='relu')) \n",
        "classifier.add(MaxPooling2D(pool_size=(2,2)))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCBB5wOSMgsT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# step1->convolution\n",
        "classifier.add(Convolution2D(32,3,3,input_shape=(64,64,3),activation='relu')) # no.of filters,dimn of filter,input_shape,why relu?->no neg values and non-linear behaviour\n",
        "\n",
        "# pooling\n",
        "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "# flattening\n",
        "classifier.add(Flatten())\n",
        "\n",
        "# full connection\n",
        "classifier.add(Dense(output_dim=128,activation='relu'))  # 128 is an experiment.They are hidden nodes\n",
        "classifier.add(Dense(output_dim=1,activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeao3-6HMhW_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compiling the cnn\n",
        "classifier.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFp3NXa8RO3B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fitting the cnn \n",
        "# to prevent overfitting. We need lots of images to get correlation.Need to find patterns.10k not much enough.Create many batches of images and then transforming\n",
        "# i.e flipping,rotating. These are random. So get more images. Avoid overfitting\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/drive/My Drive/dataset/training_set',\n",
        "        target_size=(64,64),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        '/content/drive/My Drive/dataset/test_set',\n",
        "        target_size=(64,64),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOGmES8RVn1S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=8000,\n",
        "        epochs=25,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=2000)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}